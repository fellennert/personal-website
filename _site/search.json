[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "I’m Felix, a final-year Ph.D. student in Sociology at the Ecole Polytechnique in Paris, currently living in Boston with my partner and two cats. I’m a German citizen with a valid U.S. work permit.\nI hold a Bachelor’s of Arts degree in Political Science (University of Regensburg), a Master’s of Science from Linköping University, and will defend my Ph.D. in Sociology at the Ecole Polytechnique in Paris in early 2026. During my Ph.D., I also spent a year as a visiting researcher at Duke University.\nYou can find my CV below (you can also download it). If you want to get in touch, please reach out via email or LinkedIn."
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Academic Research",
    "section": "",
    "text": "What I like about the social sciences is that instead of just building models to predict outcomes, we get to dig into the why behind human behavior. Given that we all witness human behavior all the time, everyone has their own little theories of why people do what they do. The challenge of social science research is to move beyond this anecdotal evidence and figure out what actually drives behavior on a larger scale. The crux is then to communicate these insights in a way that is understandable and useful to others. On this page, I share some of the academic research projects that I conducted during my Ph.D.\n\nMediated Cues. How Elite Polarization is Transported Through the Media\nwith Väinö Yrjänäinen and Måns Magnusson\nDo people become more polarized because politicians say polarizing things in the news, or do politicians say polarizing things because people are already polarized? We studied 25 years of French newspaper coverage and public opinion surveys to find out. The answer: both happen, but it depends on the issue. For some topics, media coverage of elite politicians clearly drives public opinion. For others, politicians seem to follow where public opinion is already going. This means there’s no one-size-fits-all explanation for how political polarization spreads.\n\n\nHow Elite Negativity Shapes Voter Affect: Evidence from the 2021 German Federal Election\nsolo-authored; currently under review at German Politics\nWhen a political party attacks its opponents on Twitter, does it make voters dislike those opponents more? Using transformer models and OLS regression, I analyzed tweets from candidates in Germany’s 2021 election alongside biweekly voter survey data to find out. The answer is yes: when Party A criticizes Party B on social media, Party A’s supporters report disliking Party B more. The effect is strongest among people who already identify strongly with their party, and it holds up regardless of whether the parties might form a coalition together or how ideologically similar they are. Also, the opposite is not true: a party don’t criticize other parties more if they know that their supporters don’t like these parties.\n\n\nDo Liberals Drive Volvos Everywhere? Assessing Cultural Bundles in Sweden\nwith Anastasia Menshikova, Elida Izani Binti Ibrahim, and Miriam Hurtado Bodell; currently under review at Social Media+Society\nIn the U.S., we know that political views often cluster with lifestyle choices – like the stereotype that liberals drive Priuses. But does this happen in countries with more than two major parties? We analyzed what 12,000 politically active Swedish Twitter users follow using mixed membership clustering to see if political affiliation predicts their cultural tastes. It does. Swedish voters’ media consumption, cultural interests, religious views, and even sense of humor align with their partisan identity. Political polarization isn’t just about policy disagreements – it’s seeping into everyday lifestyle choices, even in a multi-party democracy like Sweden.\n\n\nMedia Slant as Political Refraction. Measuring Political Media Slant and Polarization in the French Media Landscape\nwith Rubing Shen, Arnault Chatelain, and Etienne Ollion\nHow can we measure whether a newspaper leans left or right without relying on subjective judgments? We developed a new method that analyzes how journalists talk about political issues differently than politicians do. By looking at subtle differences in word choice and framing, we can detect political bias at a very fine level, down to individual paragraphs. We tested this on major French newspapers from 2000-2010 and found that mainstream media became increasingly polarized during this period. This gives researchers and the public a tool to track media bias objectively over time.\n\n\nPerceptions of Intergenerational Mobility in Germany, Sweden, and the UK: Insights from Machine-Learning Text Analysis\nwith Alexi Gugushvili and Patrick Präg; preprint; currently under review at European Journal of Sociology\nWhen people compare their lives to their parents’, what are they actually comparing? We used LLMs and clustering-algorithms to analyze thousands of open-ended survey responses from Germany, Sweden, and the UK. While traditional research focuses on income, education, and job status, we found that people think about much more: home ownership, family life, freedom, lifestyle choices, and opportunities. What matters also varies dramatically by country: Swedes emphasize education, Brits focus on housing, Germans talk about freedom and lifestyle. Gender matters too: women are more likely to mention education and family, while men focus on income and career. Understanding what people actually care about when they think about social mobility gives us a richer picture than traditional metrics alone."
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Personal Website",
    "section": "",
    "text": "Portrait of Felix\n\n\nHi! My name is Felix and this is my personal website. I am a final-year Ph.D. student in Sociology at the Ecole Polytechnique in Paris. I live in Boston with my partner (who is doing her Ph.D. in Sociology, too) and two gorgeous cats. I am a German citizen and have a valid work permit for the U.S.\nI spent years doing research in the field of cultural and political sociology, asking big questions about human behavior and waiting even longer for answers. This career gave me great opportunities: I lived in Germany, Sweden, France, and the U.S., I met great and interesting people, and learned a lot. However, between endless research timelines, publishing and revision cycles, and the slow churn of academic life, I also realized that I was craving something different: the chance to see my work make an impact more immediately and directly. Who cares about a ten-page journal article that gets 1,000 downloads and maybe influences a few other researchers if it doesn’t change anything in the real world?\nThe closest you can get to experiencing impact in academia is through teaching and conference visits. I have been teaching younger folks how to go after social science questions in R and Python throughout my entire academic career (starting right after graduating from my Bachelor’s program) and also attended and presented at more than 10 academic conferences. These occasions showed me what I love most about this work: solving problems and telling stories with data. There is nothing I enjoy more than the moment when a visualization clicks, when a pattern emerges from messy data, when numbers suddenly tell a story that changes how someone sees a problem. I want to do that outside the university, with data that’s as exciting and dynamic as the questions it can answer.\nThat desire for real-world impact led me to work as a consulting analyst for Statistical Horizons, where I got my first taste of what data work looks like outside academia. I crunched performance data for reports and dashboards, prepared marketing campaigns using customer data that I collected online, and created reports that made an immediate and measurable impact. It confirmed what I suspected: I want to do this full-time.\nSo I am looking for data analyst and data science roles where I can combine rigorous methodology with practical problem-solving. Where I can dive into rich datasets, uncover insights that actually shift decisions, and communicate findings in ways that resonate with and help the people who need them.\nThis portfolio is a glimpse of how I work – curious, methodical, sometimes a bit outside the box, but always driven by a desire to understand and explain. If you like what you see here, please reach out. I would love to connect and explore how I can bring this approach to your team."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "This section is where theory meets practice. Each project here represents a different slice of what I bring to data work: collecting messy data from the web, building and comparing machine learning models, applying cutting-edge NLP techniques, creating interactive tools to make my partner happy, and making complex methods accessible to others.\nSome of these grew out of pure curiosity (what patterns emerge in song lyrics? Can we detect “eras”?), others from practical needs (how do I make my teaching materials easily searchable for my students?), and a few from different research challenges (what is the best classifier for a job? how good are LLMs actually? is political polarization really so hot?). Together, they show how I approach problems: I start with a question, pick the right tools and data for the job, and don’t stop until I’ve found an answer worth sharing.\nYou’ll see a mix of techniques here: classic machine learning, modern transformer models, web scraping, interactive dashboards, and RAG applications. But the thread that runs through all of them is the same: how can I turn raw data into understandable insights, into something people can actually understand and use.\n\nPolarization terms\nThis emerged as part of writing the introductory chapter for my dissertation on political polarization. Political polarization has been coined “Word of the Year 2024” by Merriam Webster, reflecting the search traffic on their page. I was wondering whether there would be different ways to document such a surge in attention. Therefore, I moved to Google Trends (“are people interested in political polarization?”), Google Scholar (“are researchers interested in political polarization?”), and the New York Times API (“are journalists interested in political polarization?”). Turns out, yes, and there’s been an overall increase in attention. This summary can serve as an example of how to scrape valuable data sources and navigate obstacles such as CAPTCHAs. [READ MORE HERE.]\n\n\nTraining and comparing ML classifiers\nOne topic of a graduate class I taught on Computational Social Science was supervised classification of text. I showed the students different approaches for doing this (simple, dictionary-based; more advanced, using bag-of-words-based models; and advanced, using BERT). To show the students how capable these different models are, I decided to train and compare several machine learning classifiers. Due to time constraints, I resorted to a pre-labeled data set that was available on Kaggle, containing IMDb reviews of movies. Here’s a little report on my results, with an emphasis on the impact of preprocessing and the number of training examples. [READ MORE HERE.]\n\n\nBERTopic on survey responses\nFor a research paper, I needed to analyze open-ended survey responses. They came with particular challenges: (a) they were very short, rendering “classic” mixed membership models useless; (b) they came in three different languages (English, German, Swedish). To classify the responses into different “topics”, I decided to use BERTopic, a modern topic modeling approach based on transformer embeddings. This approach also allowed me to pre-specify topics based on prior research, making it particularly useful for theory-guided research where you already have an idea of what’s in the text. [READ MORE HERE.]\n\n\nShiny advent calendar\nPh.D. students do not have tremendous purchasing power and my partner and I had to live in different places for a year. However, I knew that I would come back to Durham, NC (where she lived at the time) and we would spend spring and summer together. To make the distance and wait more bearable, I created a Shiny app that served as an advent calendar for us. Each day, a new suggestion for a shared “date activity” would pop up, like a boat rental or a nice restaurant. It was a fun way to combine my coding skills with a personal touch, and it made the holiday season special despite the distance. [READ MORE HERE.]\n\n\nTaylor Swift lyrics\nI can’t say that I have been a Taylor Swift fan since her early days. However, I will readily admit that her songwriting does a tremendous job at capturing the lived experience of a Millenial and as she aged her songs also matured (and there are all these fun Shakespeare references). I was curious whether I could find patterns in her lyrics that correspond to different “eras” of her music career. The data were readily available, neatly wrapped in an R package, so I processed the text, and went to town with various NLP techniques to see if distinct themes or styles emerged over time. [READ MORE HERE.]\n\n\nRAG of teaching materials\nTo help my students prepare for their final papers and making a “more targeted” GPT for them, I wanted to create a Retrieval-Augmented Generation (RAG) system that could answer their questions based on the materials I provided throughout the semester. This involved collecting lecture notes, slides, and reading materials, casting them into a machine-readable format, and then setting up a RAG pipeline that could retrieve relevant information, coupled with a local LLM to generate coherent answers. The goal was to make studying more interactive and efficient for my students. [READ MORE HERE.]\n\n\nTranscription tutorial\nSocial scientists use plenty of text data for their research due to the fact that its readily available and easily analyzable. However, an in my experience often overlooked source of text data are audio or video recordings. Interviews, focus groups, speeches, and even podcasts can be treasure troves of data. To help fellow researchers get started with transcribing audio data into text, I created a tutorial that walks through the process using popular tools and services. The tutorial covers everything from speaker diarization with pyannote (for instance, if you have interview or focus group recordings) to using a large model in the background (OpenAI Whisper) to ensure high accuracy in your transcriptions. Unlike tools, such as Zoom’s transcription software, my approach is fully free and the data will not be used for training the providers’ models – making it well-suited for sensitive data. [READ MORE HERE.]\n\n\nUsing LLMs for coding qualitative data\nQualitative data analysis often involves coding text data into different categories or themes. This can be a time-consuming and subjective process. To explore how large language models (LLMs) can assist in this task, I set up an experiment where I used an LLM to code a set of qualitative data and compared its performance to a human coder (me). The goal was to assess the accuracy, consistency, and efficiency of using LLMs for qualitative coding, and to identify potential benefits and limitations of this approach. The approach I suggest works across languages (depending on LLM choice), is fairly quick and robust. Also, it runs locally (at least on my 2022 MacBook Pro M1 Pro), thus the data will never be shared with other companies (e.g., OpenAI, Anthropic). [READ MORE HERE.]"
  }
]